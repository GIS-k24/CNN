"""
环境：
      torch                         1.2.0+cpu
      torchvision                   0.4.0+cpu

根据实际需求，神经网络出现结构上的优化：

CNN--神经网络对图像处理产生的结构上的优化

常规的网络使用：网络初始化-->测试数据输入-->网络训练完成

对于CNN，测试的数据将是图片，MNIST数据集是8bit图片，通常使用的图片都是RGB类型，相当于3张8bit图片，假设一张1000*1000的RGB图片，像素点有1000*1000*3，这样网络的训练将十分麻烦

因此还需要进行数据预处理
传统方法处理图片：将图片模糊化【对图片进行量化】，过程为：
RGB图片-->3个2维矩阵
要模糊化图片，相当于做矩阵的乘法，这里需要使用一个3*3的矩阵，如下【称为kernel，也就是“核”】：
[0   0.2   0
0.2  0.2  0.2
 0   0.2   0]
 kernel和矩阵的作用过程为“卷积”
 
 关于卷积过程：
    “卷积核” = kernel；
    “卷积的大小” = kernel size；
    “卷积核在矩阵上横向和纵向上一次移动的大小” = stride
    
 关于原始图片：
     RGB图像，大小为（h,w），形状是（h,w,3）
     "3"是输入图像的“深度”
     因此对于卷积核需要改变为（3,h',w'），3是“输入通道”
     
 关于卷积过程：
     例：用一个6 * 6的矩阵和kernel进行卷积（kernel size = 3 * 3，stride = 1）将会得到一个5 * 5的矩阵
     如此一来，图片莫名其妙的变小了，为了防止出现上述问题
     对6 * 6的矩阵进行外层补0，这样就可以得到6 * 6的矩阵
     
     从上述案例，矩阵外部补0（可以补多层0），层数称为padding
     
     由此：得到进行一次卷积输出后矩阵大小的计算公式：
            W_out = [(W - K + 2P) / S] + 1 
     
     作为神经网络的隐藏层，可以在卷积操作后添加激活函数 --> 一个完整的卷积层
     
 关于池化过程：
     例：有如下矩阵：       
            1   1   2   4      
            5   6   7   8       
            3   2   1   0       
            1   2   3   4       
        进行2*2的分割：
            1   1  |  2   4
            5   6  |  7   8
            -------|-------
            3   2  |  1   0
            1   2  |  3   4                          
        最大值池化则是：
            6   8
            3   4
     池化和卷积的不同之处：仅统计，无参数
     池化核的大小称为：池化核的大小（如案例中的2 * 2）
     池化在原图上移动的步长称作：池化核的移动步长
     
 总结：卷积神经网络的定义：“卷积层”+“池化层” = “隐藏层”
 
卷积例子：torch.nn.Conv2d
池化例子：torch.nn.MaxPool2d
"""

from PIL import Image
import numpy as np
import torch
from torch import nn
from torch.autograd import Variable
import torch.nn.functional as F
import matplotlib.pyplot as plt

im = Image.open("D:\编程\python\PyTorch\img\cat.png").convert('L')
# plt.imshow(im)
# plt.show()
im = np.array(im, dtype='float32')
# print(im)
im = torch.from_numpy(im.reshape((1, 1, im.shape[0], im.shape[1])))  # 适配卷积输入的要求

conv1 = nn.Conv2d(1, 1, 3, bias=False)  # 输入通道数|输出通道数【卷积核大小--由于图片转为单波段，由此为1】

sobel_kernel = np.array([[-1, -1, -1], [-1, 8, -1, ], [-1, -1, -1]], dtype='float32')  # kernel
sobel_kernel = sobel_kernel.reshape((1, 1, 3, 3))  # 适配卷积输入的要求-->输入通道|输出通道|卷积核长|卷积核宽
conv1.weight.data = torch.from_numpy(sobel_kernel)  # 给kernel赋值（此处是自定义）

edge1 = conv1(Variable(im))
edge1 = edge1.data.squeeze().numpy()  # 将输出转换为图片的格式

"""
# 自定义函数--展示卷积结果
print(edge1)
plt.imshow(edge1)
plt.show()
"""

"""
# 使用PyTorch接口处理--展示卷积结果
weight = Variable(torch.from_numpy(sobel_kernel))
edge2 = F.conv2d(Variable(im), weight)
edge2 = edge2.data.squeeze().numpy()
plt.imshow(edge2)
plt.show()
"""

# 使用nn.Conv2d()相当于直接定义一层卷积网络结构，使用F.conv2d()相当于定义一个卷积操作，由此后者需要额外定义一个weight，前者会随机定义一个weight【由此前者比较方便】。

pool1 = nn.MaxPool2d(2, 2)  # 池化层-->池化核|池化步长
print('before max pool, image shape:{}*{}'.format(im.shape[2], im.shape[3]))

small_im1 = pool1(Variable(im))
small_im1 = small_im1.data.squeeze().numpy()
print('before max pool, image shape:{}*{}'.format(small_im1.shape[0], small_im1.shape[1]))
plt.imshow(small_im1)
plt.show()

small_im2 = F.max_pool2d(Variable(im), 2, 2)
small_im2 = small_im2.data.squeeze().numpy()
plt.imshow(small_im2)
plt.show()

# 使用nn.MaxPool2d(2, 2)操作更少，通常使用nn.MaxPool2d()
